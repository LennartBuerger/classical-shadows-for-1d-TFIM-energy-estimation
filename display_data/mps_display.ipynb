{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch as pt\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path('../deterministic'))\n",
    "from deterministic.mps import MPS\n",
    "import src.constants as constants\n",
    "from display_data.data_acquisition_shadow import derandomized_classical_shadow, randomized_classical_shadow\n",
    "from display_data.prediction_shadow import estimate_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS None:\n",
      "\tvisible_num = 10\n",
      "\tphys_dims = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "\tbond_dims = [2, 4, 8, 16, 32, 16, 8, 4, 2]\n",
      "\text_bond_dims = [1, 2, 4, 8, 16, 32, 16, 8, 4, 2, 1]\n",
      "\torth_idx = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qubit_num = 10\n",
    "psi = pt.rand(2**qubit_num, dtype=pt.cdouble)\n",
    "mps = MPS.from_state_vector(qubit_num, psi)\n",
    "print(mps)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#generate a random tensor list\n",
    "qubit_num = 12\n",
    "bond_dim = 50\n",
    "tensor_liste = [pt.rand([1, 2, bond_dim], dtype=pt.cdouble)]\n",
    "for idx in range(qubit_num - 2):\n",
    "    tensor_liste.append(pt.rand([bond_dim, 2, bond_dim], dtype=pt.cdouble))\n",
    "tensor_liste.append(pt.rand([bond_dim, 2, 1], dtype=pt.cdouble))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.5081e+11+1.5233e-05j]], dtype=torch.complex128)\n"
     ]
    }
   ],
   "source": [
    "#compute the norm of the tensor network\n",
    "def norm(qubit_num, tensor_list):\n",
    "    result = pt.einsum('abc,abj->cj', tensor_list[0], tensor_list[0].conj())\n",
    "    for idx in range(1, qubit_num-1):\n",
    "        result = pt.einsum('cj,cab->jab', result, tensor_list[idx])\n",
    "        result = pt.einsum('jab,jad->bd', result, tensor_list[idx].conj())\n",
    "    result = pt.einsum('ab,acj->bcj', result, tensor_list[qubit_num - 1])\n",
    "    result = pt.einsum('bcj,bci->ji', result, tensor_list[qubit_num - 1].conj())\n",
    "    return pt.sqrt(result)\n",
    "\n",
    "print(norm(qubit_num=10, tensor_list=tensor_liste))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8514e+15+0.0196j, dtype=torch.complex128)\n"
     ]
    }
   ],
   "source": [
    "mps = MPS.from_tensor_list(tensor_liste)\n",
    "print(mps.norm())\n",
    "# -> the result is the same as it should be"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[25.9219+0.j]], dtype=torch.complex128)\n"
     ]
    }
   ],
   "source": [
    "print(norm(10, mps.tensors))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#make tensor specified by idx center of orthogonality\n",
    "def canonicalise(tensor_list, idx, D):\n",
    "    #from the left\n",
    "    for index in range(0, idx):\n",
    "        bond_dim_left = tensor_list[index][:,0,0].size()[0]\n",
    "        bond_dim_right = tensor_list[index][0,0,:].size()[0]\n",
    "        Qm, R = pt.linalg.qr(tensor_list[index].reshape(bond_dim_left*D, bond_dim_right))\n",
    "        tensor_list[index] = pt.reshape(Qm, (bond_dim_left, D, Qm.size()[1]))\n",
    "        tensor_list[index + 1] = pt.einsum('ab,bcd->acd', R, tensor_list[index + 1])\n",
    "    for index in range(idx, len(tensor_list) - 1):\n",
    "        index = len(tensor_list) - 1 - index + idx #because we want to start from the right\n",
    "        bond_dim_left = tensor_list[index][:,0,0].size()[0]\n",
    "        bond_dim_right = tensor_list[index][0,0,:].size()[0]\n",
    "        Qm_t, R_t = pt.linalg.qr(pt.t(tensor_list[index].reshape(bond_dim_left, bond_dim_right * D)))\n",
    "        Qm = pt.t(Qm_t)\n",
    "        R = pt.t(R_t)\n",
    "        tensor_list[index] = pt.reshape(Qm, (Qm_t.size()[1], D, bond_dim_right))\n",
    "        tensor_list[index - 1] = pt.einsum('abc,cd->abd', tensor_list[index - 1], R)\n",
    "    return tensor_list\n",
    "\n",
    "print(canonicalise(tensor_list=tensor_liste, idx=9, D=2)[9])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-2.0688e+11-3.3123e+11j],\n",
      "         [-2.0574e+11-3.2946e+11j]],\n",
      "\n",
      "        [[-2.9711e+08+2.2473e+08j],\n",
      "         [ 7.4502e+08+4.2499e+07j]]], dtype=torch.complex128)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.0636e+11, dtype=torch.float64)\n",
      "tensor([[5.0636e+11-6.6266e-05j]], dtype=torch.complex128)\n"
     ]
    }
   ],
   "source": [
    "print(pt.linalg.norm(canonicalise(tensor_list=MPS.from_tensor_list(tensor_liste).tensors, idx=4, D=2)[4]))\n",
    "print(norm(10, tensor_liste))\n",
    "# -> the results agree as they should"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def canonicalise_left_to_index(tensor_list, idx, phys_dim):\n",
    "    #from the left\n",
    "    for index in range(0, idx):\n",
    "        bond_dim_left = tensor_list[index][:,0,0].size()[0]\n",
    "        bond_dim_right = tensor_list[index][0,0,:].size()[0]\n",
    "        Qm, R = pt.linalg.qr(tensor_list[index].reshape(bond_dim_left*phys_dim, bond_dim_right))\n",
    "        tensor_list[index] = pt.reshape(Qm, (bond_dim_left, phys_dim, Qm.size()[1]))\n",
    "        tensor_list[index + 1] = pt.einsum('ab,bcd->acd', R, tensor_list[index + 1])\n",
    "    return tensor_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# sampling algorithm\n",
    "def sampling(tensor_list, qubit_num, num_samples):\n",
    "    bits_sampled = pt.zeros((qubit_num, num_samples))\n",
    "    probabilities_for_bits = pt.ones((qubit_num, num_samples))\n",
    "    canonicalised_tensors = canonicalise_left_to_index(tensor_list, qubit_num-1, 2)\n",
    "    #we only need to do this step if the MPS is not normalised\n",
    "    part_func = pt.einsum('ijk,ijl->kl', canonicalised_tensors[qubit_num-1], canonicalised_tensors[qubit_num-1].conj())[0,0]\n",
    "\n",
    "    for index in range(qubit_num):\n",
    "        idx = qubit_num - 1 -index\n",
    "        # because the probabilities for all samples is different, we cannot draw them all at once, but have to draw them one by one by looping\n",
    "        for k in range(num_samples):\n",
    "        #contract the network\n",
    "            if idx==qubit_num-1:\n",
    "                result = pt.einsum('ijl,iml->jm', canonicalised_tensors[idx], canonicalised_tensors[idx].conj())\n",
    "            else:\n",
    "                result = pt.einsum('fh,jh->fj', canonicalised_tensors[qubit_num-1][:,int(bits_sampled[qubit_num-1, k].item()),:], canonicalised_tensors[qubit_num-1][:,int(bits_sampled[qubit_num-1, k].item()),:].conj())\n",
    "                for counter in range(qubit_num - 1 - idx - 1):\n",
    "                    index = qubit_num - 1 - counter - 1\n",
    "                    result = pt.einsum('fj,df->dj', result, canonicalised_tensors[index][:,int(bits_sampled[index, k].item()),:])\n",
    "                    result = pt.einsum('dj,lj->dl', result, canonicalised_tensors[index][:,int(bits_sampled[index, k].item()),:].conj())\n",
    "                result = pt.einsum('rs,acr->acs', result, canonicalised_tensors[idx])\n",
    "                result = pt.einsum('acs,ams->cm', result, canonicalised_tensors[idx].conj())\n",
    "        #contraction done\n",
    "            prob_for_previous_bits = pt.prod(probabilities_for_bits[:,k])\n",
    "            probs = [abs(result[0,0])/part_func/prob_for_previous_bits, abs(result[1,1])/part_func/prob_for_previous_bits]\n",
    "            bits_sampled[idx, k] = pt.multinomial(pt.tensor([probs[0].real.item(), probs[1].real.item()]), 1, replacement=True)[0].item()\n",
    "            probabilities_for_bits[idx, k] = probs[int(bits_sampled[idx, k].item())]\n",
    "    return bits_sampled, probabilities_for_bits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.76 s ± 44.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sampling(tensor_liste, qubit_num, 100)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# sampling algorithm\n",
    "def sampling_one_sample(tensor_list, qubit_num):\n",
    "    bits_sampled = pt.zeros(qubit_num)\n",
    "    probabilities_for_bits = pt.ones(qubit_num)\n",
    "    #we only need to do this step if the MPS is not normalised\n",
    "    canonicalised_tensors = canonicalise_left_to_index(tensor_list, qubit_num-1, 2)\n",
    "    part_func = pt.einsum('ijk,ijl->kl', canonicalised_tensors[qubit_num-1], canonicalised_tensors[qubit_num-1].conj())[0,0]\n",
    "\n",
    "    for index in range(qubit_num):\n",
    "        idx = qubit_num - 1 -index\n",
    "        canonicalised_tensors = canonicalise_left_to_index(tensor_list, idx, 2)\n",
    "        #contract the network\n",
    "        if idx==qubit_num-1:\n",
    "            result = pt.einsum('ijl,iml->jm', canonicalised_tensors[idx], canonicalised_tensors[idx].conj())\n",
    "        else:\n",
    "            result = pt.einsum('fh,jh->fj', canonicalised_tensors[qubit_num-1][:,int(bits_sampled[qubit_num-1].item()),:], canonicalised_tensors[qubit_num-1][:,int(bits_sampled[qubit_num-1].item()),:].conj())\n",
    "            for counter in range(qubit_num - 1 - idx - 1):\n",
    "                index = qubit_num - 1 - counter - 1\n",
    "                result = pt.einsum('fj,df->dj', result, canonicalised_tensors[index][:,int(bits_sampled[index].item()),:])\n",
    "                result = pt.einsum('dj,lj->dl', result, canonicalised_tensors[index][:,int(bits_sampled[index].item()),:].conj())\n",
    "            result = pt.einsum('rs,acr->acs', result, canonicalised_tensors[idx])\n",
    "            result = pt.einsum('acs,ams->cm', result, canonicalised_tensors[idx].conj())\n",
    "        #contraction done\n",
    "        prob_for_previous_bits = pt.prod(probabilities_for_bits, dim=0)\n",
    "        probs = [abs(result[0,0])/part_func/prob_for_previous_bits, abs(result[1,1])/part_func/prob_for_previous_bits]\n",
    "        # because the probabilities for all samples is different, we cannot draw them all at once, but have to\n",
    "        bits_sampled[idx] = pt.multinomial(pt.tensor([probs[0].real.item(), probs[1].real.item()]), 1, replacement=True)[0].item()\n",
    "        probabilities_for_bits[idx] = probs[int(bits_sampled[idx].item())]\n",
    "    return bits_sampled, probabilities_for_bits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenna\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  ..\\aten\\src\\ATen\\native\\Copy.cpp:244.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.9 ms ± 1.16 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sampling_one_sample(tensor_liste, qubit_num)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# apply a rotation\n",
    "def rotation(tensoren, rotation_pauli_string):\n",
    "    rot_tensors = []\n",
    "    for idx in range(len(tensoren)):\n",
    "        rot_tensors.append(pt.einsum('ab,cbd->cad',constants.PAULI_ROT[rotation_pauli_string[idx]], tensoren[idx]))\n",
    "    return rot_tensors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# shadow generation\n",
    "def generate_shadow_and_prob(tensoren, qubit_num, number_of_measurements, num_measurements_per_rot):\n",
    "    measurement_outcomes = []\n",
    "    probabilities = []\n",
    "    measurement_procedure = randomized_classical_shadow(number_of_measurements, qubit_num)\n",
    "    for i in range(number_of_measurements):\n",
    "        tensor_list_rot = rotation(tensoren, measurement_procedure[i])\n",
    "        measurement_bits, probs = sampling(tensor_list_rot, qubit_num, num_measurements_per_rot)\n",
    "        probabilities.append(pt.prod(probs, dim = 0))\n",
    "        #convert binary torch tensor to index\n",
    "        measurement_outcome = pt.zeros(num_measurements_per_rot, dtype = pt.int)\n",
    "        for k in range(0, qubit_num):\n",
    "            measurement_outcome[:] = measurement_outcome + measurement_bits[k] * 2**(qubit_num - 1 - k)\n",
    "        measurement_outcomes.append(measurement_outcome)\n",
    "    return measurement_outcomes, measurement_procedure, probabilities"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10.271340669263154\n"
     ]
    }
   ],
   "source": [
    "# now we have a method to keep only the unique indices, now we convert the measurements to the necessary shape for shadow prediction\n",
    "meas_outcomes, meas_procedure, probs = generate_shadow_and_prob(tensor_liste, qubit_num, 100, 20)\n",
    "energies = np.zeros(len(meas_outcomes))\n",
    "for n in range(len(meas_outcomes)):\n",
    "    # first get the unique elements of this torch tensor\n",
    "    unique_meas_outcomes, index_perm = np.unique(meas_outcomes[n].numpy(), return_index=True)\n",
    "    probs_sorted = probs[n][index_perm]\n",
    "    measurements = conversion_to_prediction_shadow_dict_shape([meas_procedure[n]]*len(unique_meas_outcomes), unique_meas_outcomes, qubit_num)\n",
    "    energies[n] = ising_energy_shadows(measurements, probs_sorted, qubit_num, 0.1)\n",
    "energy = np.mean(energies)\n",
    "print(energy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# this function converts the stored measurement outcomes to the correct shape needed for the shadow prediction\n",
    "def conversion_to_prediction_shadow_dict_shape(measurement_procedure, measurement_index, qubit_num):\n",
    "    to_str_func = np.vectorize(lambda x: np.binary_repr(x).zfill(qubit_num))\n",
    "    strs = to_str_func(measurement_index)\n",
    "    dirac_rep = np.zeros(list(measurement_index.shape) + [qubit_num], dtype=np.int8)\n",
    "    for bit_ix in range(0, qubit_num):\n",
    "        fetch_bit_func = np.vectorize(lambda x: x[bit_ix] == '1')\n",
    "        dirac_rep[...,bit_ix] = fetch_bit_func(strs).astype(\"int8\")\n",
    "    measurement_array = np.where(dirac_rep == 1, -1, dirac_rep)\n",
    "    measurement_array = np.where(dirac_rep == 0, 1, measurement_array)\n",
    "    measurement = np.dstack((measurement_procedure, np.array(measurement_array, dtype=int)))\n",
    "    return measurement"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#now we estimate the energy from the classical shadows, we pick the open boundary TFIM Hamiltonian\n",
    "def ising_energy_shadows(measurements, probabilities, qubit_num, ratio_h_J):\n",
    "    h_val = ratio_h_J\n",
    "    j_val = 1\n",
    "    observables = []\n",
    "    for i in range(0, qubit_num):\n",
    "        x_arr = [['X', i]]\n",
    "        observables.append(x_arr)\n",
    "        if i <= qubit_num - 2:\n",
    "            z_arr = [['Z', i], ['Z', i + 1]]\n",
    "            observables.append(z_arr)\n",
    "\n",
    "    energy = 0\n",
    "    for j in range(len(measurements)):\n",
    "        for i in range(0, len(observables)):\n",
    "            sum_product, cnt_match = estimate_exp([measurements[j]], observables[i])\n",
    "            if sum_product == 0 and cnt_match == 0:\n",
    "                expectation_val = 0\n",
    "            elif cnt_match == 0 and sum_product != 0:\n",
    "                print('cnt_match is zero (problemo)!')\n",
    "            else:\n",
    "                expectation_val =  sum_product / cnt_match * probabilities[j]\n",
    "            if i % 2 == 0:\n",
    "                energy = energy + h_val * expectation_val * 3 # weighing with factor 3**locality to counteract the chance of hitting\n",
    "            else:\n",
    "                energy = energy + j_val * expectation_val * 3**2\n",
    "\n",
    "    energy = energy / pt.sum(probabilities).item()\n",
    "    return energy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "def energy_shadow(measurement, ratio_h_j, qubit_num):\n",
    "    observables = []\n",
    "    for i in range(0, qubit_num):\n",
    "        x_arr = [['X', i]]\n",
    "        observables.append(x_arr)\n",
    "        if i <= qubit_num - 2:\n",
    "            z_arr = [['Z', i], ['Z', i + 1]]\n",
    "            observables.append(z_arr)\n",
    "\n",
    "    # now we have our measurement outcome and our observables stored in the correct format\n",
    "    energy = 0\n",
    "    for i in range(0, len(observables)):\n",
    "        sum_product, cnt_match = estimate_exp(measurement, observables[i])\n",
    "        if sum_product == 0 and cnt_match == 0:\n",
    "            expectation_val = 0\n",
    "        elif cnt_match == 0 and sum_product != 0:\n",
    "            print('cnt_match is zero (problemo)!')\n",
    "        else:\n",
    "            expectation_val = sum_product / cnt_match\n",
    "        if i % 2 == 0:\n",
    "            energy = energy + ratio_h_j * expectation_val\n",
    "        else:\n",
    "            energy = energy + expectation_val\n",
    "    return energy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "ratio_h_j = 0.1\n",
    "qubit_num = 6\n",
    "save_direc_groundstate = Path('data/Diagonal_hamiltonian/groundstate_dict.npy')\n",
    "ground_state_dict = np.load(save_direc_groundstate, allow_pickle='TRUE')\n",
    "ground_state_dict = ground_state_dict.item()\n",
    "ground_state = ground_state_dict[str(1)]['open'][str(qubit_num)][str(ratio_h_j)]\n",
    "mps = MPS.from_state_vector(qubit_num, ground_state)\n",
    "tensor_liste = mps.tensors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.020016662087988\n"
     ]
    }
   ],
   "source": [
    "save_direc_eigs = Path('data/Diagonal_hamiltonian/eigenvalues_first_three_dict.npy')\n",
    "energy_dict = np.load(save_direc_eigs, allow_pickle=True)\n",
    "energy_dict = energy_dict.item()\n",
    "energy_brute = energy_dict[str(1)]['open'][str(qubit_num)][str(ratio_h_j)][0]\n",
    "print(energy_brute)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# now we have a method to keep only the unique indices, now we convert the measurements to the necessary shape for shadow prediction\n",
    "batches = 3\n",
    "num_of_measurements = np.array([10, 20, 50, 100, 200, 300, 500])\n",
    "num_of_measurements_per_rot = 20\n",
    "energies_different_meas_num = np.zeros((np.size(num_of_measurements), batches))\n",
    "for b in range(batches):\n",
    "    for i in range(np.size(num_of_measurements)):\n",
    "        meas_outcomes, meas_procedure, probs = generate_shadow_and_prob(tensor_liste, qubit_num, num_of_measurements[i], num_of_measurements_per_rot)\n",
    "        energies = np.zeros(len(meas_outcomes))\n",
    "        for n in range(len(meas_outcomes)):\n",
    "            # first get the unique elements of this torch tensor\n",
    "            unique_meas_outcomes, index_perm = np.unique(meas_outcomes[n].numpy(), return_index=True)\n",
    "            probs_sorted = probs[n][index_perm]\n",
    "            measurements = conversion_to_prediction_shadow_dict_shape([meas_procedure[n]]*len(unique_meas_outcomes), unique_meas_outcomes, qubit_num)\n",
    "            energies[n] = ising_energy_shadows(measurements, probs_sorted, qubit_num, 0.1)\n",
    "        energy = np.mean(energies)\n",
    "        energies_different_meas_num[i,b] = energy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rel_error = np.abs((energies_different_meas_num - energy_brute) / energy_brute)\n",
    "rel_error_mean = np.mean(rel_error, axis=1)\n",
    "rel_error_std = np.mean(rel_error, axis=1)\n",
    "plt.plot(num_of_measurements, rel_error_mean)\n",
    "plt.fill_between(num_of_measurements, rel_error_mean - rel_error_std, rel_error_mean + rel_error_std)\n",
    "plt.yscale('log')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}